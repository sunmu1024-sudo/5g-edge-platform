"""
æ‘„åƒå¤´ä¼ æ„Ÿå™¨å®ç°
æ”¯æŒçœŸå®æ‘„åƒå¤´å’Œæ¨¡æ‹Ÿå›¾åƒç”Ÿæˆ
"""

import cv2
import numpy as np
from datetime import datetime
import os
import json
import random
from PIL import Image, ImageDraw, ImageFont
import io
import base64

class CameraSensor:
    """æ‘„åƒå¤´ä¼ æ„Ÿå™¨"""
    
    def __init__(self, sensor_id, location, camera_index=0, mode='simulation'):
        """
        åˆå§‹åŒ–æ‘„åƒå¤´ä¼ æ„Ÿå™¨
        
        Args:
            sensor_id: ä¼ æ„Ÿå™¨ID
            location: å®‰è£…ä½ç½®
            camera_index: æ‘„åƒå¤´ç´¢å¼•ï¼ˆ0=é»˜è®¤æ‘„åƒå¤´ï¼‰
            mode: è¿è¡Œæ¨¡å¼ ('real'=çœŸå®æ‘„åƒå¤´, 'simulation'=æ¨¡æ‹Ÿæ¨¡å¼)
        """
        self.sensor_id = sensor_id
        self.location = location
        self.sensor_type = "camera"
        self.unit = "image"
        self.camera_index = camera_index
        self.mode = mode
        self.cap = None
        self.frame_count = 0
        self.last_capture_time = None
        
        # æ¨¡æ‹Ÿæ•°æ®å‚æ•°
        self.simulation_scenes = ['office', 'laboratory', 'outdoor', 'night']
        self.current_scene = 'laboratory'
        
        # åˆå§‹åŒ–æ‘„åƒå¤´
        if mode == 'real':
            self._initialize_real_camera()
        else:
            print(f"ğŸ® æ‘„åƒå¤´ {sensor_id} è¿è¡Œåœ¨æ¨¡æ‹Ÿæ¨¡å¼")
    
    def _initialize_real_camera(self):
        """åˆå§‹åŒ–çœŸå®æ‘„åƒå¤´"""
        try:
            self.cap = cv2.VideoCapture(self.camera_index)
            if not self.cap.isOpened():
                print(f"âŒ æ— æ³•æ‰“å¼€æ‘„åƒå¤´ {self.camera_index}ï¼Œåˆ‡æ¢åˆ°æ¨¡æ‹Ÿæ¨¡å¼")
                self.mode = 'simulation'
                self.cap = None
            else:
                # è®¾ç½®æ‘„åƒå¤´å‚æ•°
                self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
                self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
                self.cap.set(cv2.CAP_PROP_FPS, 30)
                print(f"âœ… æ‘„åƒå¤´ {self.camera_index} åˆå§‹åŒ–æˆåŠŸ")
                
        except Exception as e:
            print(f"âŒ æ‘„åƒå¤´åˆå§‹åŒ–å¤±è´¥: {e}")
            self.mode = 'simulation'
            self.cap = None
    
    def _generate_simulation_frame(self, width=640, height=480):
        """ç”Ÿæˆæ¨¡æ‹Ÿæ‘„åƒå¤´å¸§"""
        # åˆ›å»ºç©ºç™½å›¾åƒ
        if self.current_scene == 'office':
            # åŠå…¬å®¤åœºæ™¯ - åäº®çš„èƒŒæ™¯
            background_color = (240, 240, 245)  # æµ…ç°è‰²
            text_color = (50, 50, 50)  # æ·±ç°è‰²
        elif self.current_scene == 'laboratory':
            # å®éªŒå®¤åœºæ™¯ - åå†·çš„èƒŒæ™¯
            background_color = (220, 240, 255)  # æµ…è“è‰²
            text_color = (30, 80, 120)  # æ·±è“è‰²
        elif self.current_scene == 'outdoor':
            # æˆ·å¤–åœºæ™¯ - åæš–çš„èƒŒæ™¯
            background_color = (255, 245, 235)  # æµ…é»„è‰²
            text_color = (100, 70, 30)  # æ£•è‰²
        else:  # night
            # å¤œæ™šåœºæ™¯ - æš—è‰²èƒŒæ™¯
            background_color = (50, 50, 70)  # æ·±è“è‰²
            text_color = (200, 200, 220)  # æµ…ç°è‰²
        
        # åˆ›å»ºPILå›¾åƒ
        pil_image = Image.new('RGB', (width, height), background_color)
        draw = ImageDraw.Draw(pil_image)
        
        # æ·»åŠ ä¸€äº›éšæœºå…ƒç´ æ¨¡æ‹ŸçœŸå®åœºæ™¯
        self._add_simulation_elements(draw, width, height)
        
        # æ·»åŠ æ—¶é—´æˆ³å’Œä¿¡æ¯
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        info_text = f"æ‘„åƒå¤´: {self.sensor_id} | ä½ç½®: {self.location} | åœºæ™¯: {self.current_scene}"
        
        # æ·»åŠ æ–‡å­—ï¼ˆç®€åŒ–ç‰ˆï¼Œä¸ä½¿ç”¨å­—ä½“æ–‡ä»¶ï¼‰
        draw.rectangle([10, 10, width-10, 50], fill=(0, 0, 0, 128))
        draw.text((15, 15), timestamp, fill=(255, 255, 255))
        draw.text((15, 35), info_text, fill=(200, 200, 255))
        
        # è½¬æ¢ä¸ºOpenCVæ ¼å¼
        cv_image = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)
        
        return cv_image
    
    def _add_simulation_elements(self, draw, width, height):
        """æ·»åŠ æ¨¡æ‹Ÿåœºæ™¯å…ƒç´ """
        # éšæœºæ·»åŠ ä¸€äº›çŸ©å½¢æ¨¡æ‹Ÿç‰©ä½“
        for _ in range(random.randint(3, 8)):
            x1 = random.randint(0, width-100)
            y1 = random.randint(0, height-100)
            x2 = x1 + random.randint(50, 150)
            y2 = y1 + random.randint(50, 150)
            
            color = (
                random.randint(50, 200),
                random.randint(50, 200), 
                random.randint(50, 200)
            )
            
            draw.rectangle([x1, y1, x2, y2], fill=color, outline=(0, 0, 0), width=2)
        
        # æ·»åŠ ä¸€äº›çº¿æ¡æ¨¡æ‹Ÿè¾¹ç¼˜
        for _ in range(random.randint(2, 5)):
            x1 = random.randint(0, width)
            y1 = random.randint(0, height)
            x2 = random.randint(0, width)
            y2 = random.randint(0, height)
            
            draw.line([x1, y1, x2, y2], fill=(100, 100, 100), width=2)
    
    def capture_frame(self, save_to_file=False, save_path="captures"):
        """æ•è·ä¸€å¸§å›¾åƒ"""
        try:
            if self.mode == 'real' and self.cap and self.cap.isOpened():
                # ä»çœŸå®æ‘„åƒå¤´æ•è·
                ret, frame = self.cap.read()
                if not ret:
                    print("âŒ æ— æ³•ä»æ‘„åƒå¤´è¯»å–å¸§")
                    return None
            else:
                # ç”Ÿæˆæ¨¡æ‹Ÿå¸§
                frame = self._generate_simulation_frame()
            
            self.frame_count += 1
            self.last_capture_time = datetime.now()
            
            # å¦‚æœéœ€è¦ä¿å­˜åˆ°æ–‡ä»¶
            if save_to_file:
                self._save_frame_to_file(frame, save_path)
            
            return frame
            
        except Exception as e:
            print(f"âŒ æ•è·å›¾åƒå¤±è´¥: {e}")
            return None
    
    def _save_frame_to_file(self, frame, save_path):
        """ä¿å­˜å¸§åˆ°æ–‡ä»¶"""
        try:
            if not os.path.exists(save_path):
                os.makedirs(save_path)
            
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"{self.sensor_id}_{timestamp}.jpg"
            filepath = os.path.join(save_path, filename)
            
            cv2.imwrite(filepath, frame)
            print(f"âœ… å›¾åƒå·²ä¿å­˜: {filepath}")
            
        except Exception as e:
            print(f"âŒ ä¿å­˜å›¾åƒå¤±è´¥: {e}")
    
    def capture_image(self, return_base64=False, analyze_image=True):
        """æ•è·å›¾åƒï¼ˆå…¼å®¹æ€§æ–¹æ³•ï¼‰"""
        frame = self.capture_frame()
        if frame is None:
            return None
        
        result = {
            'timestamp': datetime.now().isoformat(),
            'frame_info': self.get_frame_info(frame),
            'sensor_id': self.sensor_id,
            'location': self.location
        }
        
        if analyze_image:
            result['analysis'] = self.analyze_frame(frame)
        
        if return_base64:
            result['image_base64'] = self.frame_to_base64(frame)
        
        return result
    
    def get_frame_info(self, frame):
        """è·å–å¸§ä¿¡æ¯"""
        if frame is None:
            return None
            
        height, width, channels = frame.shape
        
        # è®¡ç®—ä¸€äº›åŸºæœ¬å›¾åƒç»Ÿè®¡
        avg_brightness = np.mean(frame)
        contrast = np.std(frame)
        
        # è½¬æ¢ä¸ºHSVè®¡ç®—é¥±å’Œåº¦
        hsv_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
        avg_saturation = np.mean(hsv_frame[:, :, 1])
        
        return {
            'resolution': f"{width}x{height}",
            'channels': channels,
            'file_size_estimate': width * height * channels,  # å­—èŠ‚ä¼°ç®—
            'brightness': round(avg_brightness, 2),
            'contrast': round(contrast, 2),
            'saturation': round(avg_saturation, 2),
            'frame_count': self.frame_count
        }
    
    def analyze_frame(self, frame):
        """åˆ†æå›¾åƒå¸§"""
        if frame is None:
            return None
        
        try:
            analysis = {}
            
            # è½¬æ¢ä¸ºç°åº¦å›¾
            gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            
            # è¿åŠ¨æ£€æµ‹ï¼ˆç®€å•ç‰ˆ - ä¸ä¸Šä¸€å¸§æ¯”è¾ƒï¼‰
            if hasattr(self, 'previous_frame'):
                # è®¡ç®—å¸§å·®å¼‚
                frame_diff = cv2.absdiff(self.previous_frame, gray_frame)
                motion_level = np.mean(frame_diff)
                analysis['motion_detected'] = motion_level > 10  # é˜ˆå€¼
                analysis['motion_level'] = round(motion_level, 2)
            else:
                analysis['motion_detected'] = False
                analysis['motion_level'] = 0
            
            self.previous_frame = gray_frame
            
            # è¾¹ç¼˜æ£€æµ‹
            edges = cv2.Canny(gray_frame, 50, 150)
            analysis['edge_density'] = round(np.sum(edges > 0) / edges.size, 4)
            
            # äº®åº¦åˆ†æ
            brightness = np.mean(gray_frame)
            analysis['brightness_category'] = self._categorize_brightness(brightness)
            
            # åœºæ™¯è¯†åˆ«ï¼ˆç®€åŒ–ç‰ˆï¼‰
            analysis['scene_guess'] = self._guess_scene(frame)
            
            return analysis
            
        except Exception as e:
            print(f"âŒ å›¾åƒåˆ†æå¤±è´¥: {e}")
            return None
    
    def _categorize_brightness(self, brightness):
        """åˆ†ç±»äº®åº¦æ°´å¹³"""
        if brightness < 50:
            return "dark"
        elif brightness < 100:
            return "dim" 
        elif brightness < 150:
            return "normal"
        elif brightness < 200:
            return "bright"
        else:
            return "very_bright"
    
    def _guess_scene(self, frame):
        """çŒœæµ‹åœºæ™¯ç±»å‹ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
        
        # åˆ†æé¢œè‰²åˆ†å¸ƒ
        avg_saturation = np.mean(hsv[:, :, 1])
        avg_value = np.mean(hsv[:, :, 2])
        
        if avg_value < 50:
            return "night"
        elif avg_saturation < 50:
            return "office"
        elif avg_value > 180:
            return "outdoor"
        else:
            return "laboratory"
    
    def frame_to_base64(self, frame):
        """å°†å¸§è½¬æ¢ä¸ºbase64å­—ç¬¦ä¸²"""
        try:
            # è°ƒæ•´å›¾åƒå¤§å°ä»¥å‡å°‘æ•°æ®é‡
            small_frame = cv2.resize(frame, (320, 240))
            
            # ç¼–ç ä¸ºJPEG
            retval, buffer = cv2.imencode('.jpg', small_frame, [cv2.IMWRITE_JPEG_QUALITY, 70])
            
            if retval:
                # è½¬æ¢ä¸ºbase64
                jpg_as_text = base64.b64encode(buffer).decode('utf-8')
                return f"data:image/jpeg;base64,{jpg_as_text}"
            else:
                return None
                
        except Exception as e:
            print(f"âŒ å›¾åƒç¼–ç å¤±è´¥: {e}")
            return None
    
    def change_scene(self, scene_name):
        """æ›´æ”¹æ¨¡æ‹Ÿåœºæ™¯"""
        if scene_name in self.simulation_scenes:
            self.current_scene = scene_name
            print(f"ğŸ”„ æ‘„åƒå¤´ {self.sensor_id} åœºæ™¯æ›´æ”¹ä¸º: {scene_name}")
            return True
        else:
            print(f"âŒ æœªçŸ¥åœºæ™¯: {scene_name}")
            return False
    
    def get_sensor_info(self):
        """è·å–ä¼ æ„Ÿå™¨ä¿¡æ¯"""
        status = 'online'
        if self.mode == 'real':
            status = 'online' if self.cap and self.cap.isOpened() else 'offline'
        
        return {
            'id': self.sensor_id,
            'name': f'æ‘„åƒå¤´-{self.sensor_id.split("_")[-1]}',
            'type': self.sensor_type,
            'location': self.location,
            'mode': self.mode,
            'status': status,
            'unit': self.unit,
            'frame_count': self.frame_count,
            'last_capture': self.last_capture_time.isoformat() if self.last_capture_time else 'ä»æœªæ•è·',
            'available_scenes': self.simulation_scenes,
            'current_scene': self.current_scene
        }
    
    def start_continuous_capture(self, interval=5, duration=60):
        """å¼€å§‹è¿ç»­æ•è·ï¼ˆç”¨äºç›‘æ§ï¼‰"""
        print(f"ğŸ“¹ å¼€å§‹è¿ç»­æ•è·ï¼Œé—´éš”: {interval}ç§’ï¼Œæ—¶é•¿: {duration}ç§’")
        
        import time
        start_time = time.time()
        
        while time.time() - start_time < duration:
            result = self.capture_image(analyze_image=True)
            if result:
                print(f"ğŸ“¸ æ•è·æˆåŠŸ - è¿åŠ¨: {result['analysis']['motion_detected']}")
            
            time.sleep(interval)
        
        print("ğŸ›‘ è¿ç»­æ•è·ç»“æŸ")
    
    def release(self):
        """é‡Šæ”¾æ‘„åƒå¤´èµ„æº"""
        if self.cap:
            self.cap.release()
            self.cap = None
            print(f"ğŸ”’ æ‘„åƒå¤´ {self.sensor_id} èµ„æºå·²é‡Šæ”¾")

# æµ‹è¯•å‡½æ•°
def test_camera_sensor():
    """æµ‹è¯•æ‘„åƒå¤´ä¼ æ„Ÿå™¨"""
    print("æµ‹è¯•æ‘„åƒå¤´ä¼ æ„Ÿå™¨...")
    
    # æµ‹è¯•æ¨¡æ‹Ÿæ¨¡å¼
    camera = CameraSensor("camera_001", "å®éªŒå®¤å…¥å£", mode='simulation')
    
    # è·å–ä¼ æ„Ÿå™¨ä¿¡æ¯
    info = camera.get_sensor_info()
    print("ä¼ æ„Ÿå™¨ä¿¡æ¯:", json.dumps(info, indent=2, ensure_ascii=False))
    
    # æ•è·æµ‹è¯•å›¾åƒ
    for i in range(3):
        result = camera.capture_image(analyze_image=True)
        if result:
            print(f"æ•è· #{i+1}:")
            print(f"  åˆ†è¾¨ç‡: {result['frame_info']['resolution']}")
            print(f"  äº®åº¦: {result['frame_info']['brightness']}")
            print(f"  è¿åŠ¨æ£€æµ‹: {result['analysis']['motion_detected']}")
        
        # åˆ‡æ¢åœºæ™¯
        if i == 1:
            camera.change_scene('night')
    
    camera.release()

if __name__ == "__main__":
    test_camera_sensor()